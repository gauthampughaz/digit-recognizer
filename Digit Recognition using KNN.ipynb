{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Digit Recognizer\n\nAlthough this is a computer vision problem, I created a simple model using **K-Nearest Neighbors** algorithm in this notebook to be a good starting point knowing that CNN would be a much better option. I used the **GridSearchCV** to fine tune the hyperparameters such as *\"n_neighbors\", and \"weights\"* and to perform cross-validation. Furthermore, I have used **Data Augmentation** or **Artificial Data Synthesis** technique in this notebook to boost the model's performance on the test set.\n\nPlease **upvote** if you like this notebook and share your valuable feedback.\n\nYou can find my other notebooks below:\n\n* [Disaster Tweets Classification](https://www.kaggle.com/gauthampughazh/disaster-or-not-plotly-use-tfidf-h2o-ai-automl)\n* [House Sales Price Prediction](https://www.kaggle.com/gauthampughazh/house-sales-price-prediction-svr)\n* [Titanic Survival Classification](https://www.kaggle.com/gauthampughazh/titanic-survival-prediction-pandas-plotly-keras)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # Linear algebra\nimport pandas as pd # For data manipulation\nimport json\nimport os\nimport matplotlib.pyplot as plt # For visualization\nfrom sklearn.neighbors import KNeighborsClassifier # For modelling\nfrom sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold # For evaluation and hyperparameter tuning\nfrom sklearn.metrics import confusion_matrix, classification_report # For evaluation\nfrom scipy.ndimage.interpolation import shift # For data augmentation\nfrom IPython.display import FileLink # For downloading the output file\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Peeking the data**"},{"metadata":{},"cell_type":"markdown","source":"Loading the datasets into dataframes"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\")\nsubmission_df = pd.read_csv(\"/kaggle/input/digit-recognizer/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Knowing about the features in the datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Setting up the training and testing data as numpy arrays"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train_df.iloc[:, 1:].values\ny_train = train_df.iloc[:, 0].values\nX_test = test_df.values\n\nprint(f\"X_train shape: {X_train.shape}\")\nprint(f\"y_train shape: {y_train.shape}\")\nprint(f\"X_test shape: {X_test.shape}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visualizing a single digit as a 28 X 28 image from the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"some_digit = X_train[40]\n\nsome_digit_image = some_digit.reshape(28, 28)\nprint(f\"Label: {y_train[40]}\")\nplt.imshow(some_digit_image, cmap=\"binary\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model Selection**"},{"metadata":{},"cell_type":"markdown","source":"Using **StratifiedKFold** to make test data represent samples from all classes (digits). Also, cross-validating the model with 5 folds and displaying the classification report of the model for each test fold. Using **Confusion Matrix** to get more information about the model's performance on classifying each digit correctly."},{"metadata":{"trusted":true},"cell_type":"code","source":"stratified_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nfor fold, indices in enumerate(stratified_fold.split(X_train, y_train)):\n    # Creating datasets for training and testing the model \n    X_train_, y_train_ = X_train[indices[0]], y_train[indices[0]]\n    X_test_, y_test_ = X_train[indices[1]], y_train[indices[1]]\n    \n    estimator = KNeighborsClassifier()\n    estimator.fit(X_train_, y_train_)\n    predictions = estimator.predict(X_test_)\n    \n    print(f\"Classification report for Fold {fold + 1}:\")\n    print(classification_report(y_test_, predictions, digits=3), end=\"\\n\\n\")\n    \n    print(f\"Confusion Matrix for Fold {fold + 1}:\")\n    print(confusion_matrix(y_test_, predictions), end=\"\\n\\n\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Fine-tuning the model by finding the best values for the hyperparameters (weights, n_neighbors) using GridSearchCV**"},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_params = {\n    \"weights\": ['uniform', 'distance'],\n    \"n_neighbors\": [3, 4, 5, 6, 8, 10]\n}\n\nestimator = KNeighborsClassifier()\ngrid_estimator = GridSearchCV(estimator, # Base estimator\n                              grid_params, # Parameters to tune\n                              cv=stratified_fold, # cross-validation stratergy\n                              verbose=2, # Verbosity of the logs\n                              n_jobs=-1) # Number of jobs to be run concurrently with -1 meaning all the processors\n# Fitting the estimator with training data\ngrid_estimator.fit(X_train, y_train)\n\nprint(f\"Best Score: {grid_estimator.best_score_}\", end=\"\\n\\n\")\nprint(f\"Best Parameters: \\n{json.dumps(grid_estimator.best_params_, indent=4)}\",\n      end=\"\\n\\n\")\nprint(\"Grid Search CV results:\")\nresults_df = pd.DataFrame(grid_estimator.cv_results_)\nresults_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Fitting a new model with the found hyperparameter values to the training data and making predictions on the test data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"estimator = KNeighborsClassifier(n_neighbors=4, weights='distance')\nestimator.fit(X_train, y_train)\npredictions = estimator.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Augmentation**"},{"metadata":{},"cell_type":"markdown","source":"After reshaping the pixels to 28 X 28 images, each image is shifted down, up, left and right by one pixel generating four different images for each image in the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"def shift_in_one_direction(image, direction):\n    if direction == \"DOWN\":\n        image = shift(image, [1, 0])\n    elif direction == \"UP\":\n        image = shift(image, [-1, 0])\n    elif direction == \"LEFT\":\n        image = shift(image, [0, -1])\n    else:\n        image = shift(image, [0, 1])\n\n    return image\n\n\ndef shift_in_all_directions(image):\n    reshaped_image = image.reshape(28, 28)\n\n    down_shifted_image = shift_in_one_direction(reshaped_image, \"DOWN\").reshape(1, 784)\n    up_shifted_image = shift_in_one_direction(reshaped_image, \"UP\").reshape(1, 784)\n    left_shifted_image = shift_in_one_direction(reshaped_image, \"LEFT\").reshape(1, 784)\n    right_shifted_image = shift_in_one_direction(reshaped_image, \"RIGHT\").reshape(1, 784)\n\n    return np.r_[down_shifted_image, up_shifted_image,\n                 left_shifted_image, right_shifted_image]\n\n\nX_train_add = np.apply_along_axis(shift_in_all_directions, 1, X_train).reshape(-1, 784)\ny_train_add = np.repeat(y_train, 4)\n\nprint(f\"X_train_add shape: {X_train_add.shape}\")\nprint(f\"y_train_add shape: {y_train_add.shape}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Combining the synthesized data with the actual training data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_combined = np.r_[X_train, X_train_add]\ny_train_combined = np.r_[y_train, y_train_add]\n\nprint(f\"X_train_combined shape: {X_train_combined.shape}\")\nprint(f\"y_train_combined shape: {y_train_combined.shape}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Fitting a new model with the tuned hyperparameters to the combined dataset**"},{"metadata":{"trusted":true},"cell_type":"code","source":"cdata_estimator = KNeighborsClassifier(n_neighbors=4, weights='distance')\ncdata_estimator.fit(X_train_combined, y_train_combined)\ncdata_estimator_predictions = cdata_estimator.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Generating the submission file**"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df[\"Label\"] = predictions\nsubmission_df.to_csv('submission.csv', index=False)\nFileLink('submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df[\"Label\"] = cdata_estimator_predictions\nsubmission_df.to_csv('cdata_submission.csv', index=False)\nFileLink('cdata_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Note:** With **Data Augmentation** the accuracy jumped from 97.185% to 98.128% on the test data."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}